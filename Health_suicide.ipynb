{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Health_suicide.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyaX96sSZi3awFE8MBrkix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergyRams/A1-Introduccion-a-Bases-de-datos/blob/master/Health_suicide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUEltDxFhFda"
      },
      "source": [
        "#Chat bot program"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yVBd29ChVKU",
        "outputId": "6f66b7a0-ccbb-4f42-b4dd-36493299ed20"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYFrnz-FhfPU",
        "outputId": "680f3c68-8b24-4ab0-b74a-7aceaf55f945"
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 9.6MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 6.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 7.2MB/s \n",
            "\u001b[?25hCollecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.1->newspaper3k) (1.15.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Building wheels for collected packages: feedfinder2, jieba3k, tinysegmenter, sgmllib3k\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3355 sha256=8b8478d29eec07620f2b1029dca2ef4189de5151bf90d71ebb51efaa187669c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=29f6349723c6560146d2da9fe0852114a3198995e77969c06216974d7b2370b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13538 sha256=8e076dbd8e28ad2b461f10a33af7cf368bdbc77202d291443ad7113ac47322f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp36-none-any.whl size=6067 sha256=8a21f5954c65ca2470763075abe92359fbfd66405476b6f4715d9d425c9e7aee\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built feedfinder2 jieba3k tinysegmenter sgmllib3k\n",
            "Installing collected packages: cssselect, requests-file, tldextract, sgmllib3k, feedparser, feedfinder2, jieba3k, tinysegmenter, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SIZ_iZIhlyr"
      },
      "source": [
        "#Importing Libraries\n",
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import nltk \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU8ob4sijSq9",
        "outputId": "c4f7cbcf-977f-4199-f5f5-d7f6180c02fe"
      },
      "source": [
        "nltk.download('punkt', quiet=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olp5JuV2k_qF"
      },
      "source": [
        "#article = Article('https://www.mayoclinic.org/diseases-conditions/end-stage-renal-disease/symptoms-causes/syc-20354532?mc_id=google&campaign=1051355946&geo=9047094&kw=chronic%20kidney%20disease&ad=248596888980&network=g&sitetarget=&adgroup=57304957891&extension=&target=kwd-16462412&matchtype=b&device=c&account=4650938658&invsrc=spanish&placementsite=enterprise&gclid=Cj0KCQiAh4j-BRCsARIsAGeV12AtzwPZbeOIZlSHzGqfryu08GLlaZo7GVEJBHtuH9orqhLS3xSA1KQaAvirEALw_wcB')\n",
        "article = Article('https://afsp.org/risk-factors-and-warning-signs')\n",
        "article.download()\n",
        "article.parse()\n",
        "#Aplying Natural Language Processing\n",
        "article.nlp()\n",
        "corpus = article.text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tus_BhCmNIf",
        "outputId": "fdd01b86-e644-4b43-ad1f-062ec1d9e8c5"
      },
      "source": [
        "#Printing the Article\n",
        "print(corpus)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Something to look out for when concerned that a person may be suicidal is a change in behavior or the presence of entirely new behaviors. This is of sharpest concern if the new or changed behavior is related to a painful event, loss, or change. Most people who take their lives exhibit one or more warning signs, either through what they say or what they do.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz0XKbOrmehf"
      },
      "source": [
        "#Tokenization\n",
        "text = corpus\n",
        "sentence_list = nltk.sent_tokenize(text) #A list of sentences\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEZfZrQBmwu4",
        "outputId": "36168cad-bb57-4c65-d60a-d32632b67d37"
      },
      "source": [
        "# Print the list of sentences. Deploying sentences in a statement like format. \n",
        "print(sentence_list)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Something to look out for when concerned that a person may be suicidal is a change in behavior or the presence of entirely new behaviors.', 'This is of sharpest concern if the new or changed behavior is related to a painful event, loss, or change.', 'Most people who take their lives exhibit one or more warning signs, either through what they say or what they do.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2c_vgi7ugE5"
      },
      "source": [
        "# A function to return a random greeting response\n",
        "def greeting_response(text):\n",
        "  text = text.lower()\n",
        "  #Bots greeting response\n",
        "  bot_greetings = ['Buen Día Como amanecio', 'Buenos dias como se ha sentido', 'Excelente Día como ha evolucionado el paciente','hola', 'hello']\n",
        "#Users greeting\n",
        "  user_greetings = ['Hola','hola', 'Que hay','ayuda','hey','hello', 'hi', 'como esta']\n",
        "\n",
        "  for word in text.split():\n",
        "    if word in user_greetings:\n",
        "      return random.choice(bot_greetings)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4vy6Tux6j7"
      },
      "source": [
        "def index_sort(list_var):\n",
        "  length = len(list_var)\n",
        "  list_index = list(range(0, length))\n",
        "\n",
        "  x= list_var\n",
        "  for i in range(length):\n",
        "    for j in range(length):\n",
        "      if x[list_index[i]] > x[list_index[j]]:\n",
        "        #Swap\n",
        "        temp = list_index[i]\n",
        "        list_index[i] = list_index[j]\n",
        "        list_index[j] = temp\n",
        "        \n",
        "  return list_index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ2MmiOpwu3K"
      },
      "source": [
        "#Create the bots response\n",
        "def bot_response(user_input):\n",
        "  user_input = user_input.lower()\n",
        "  sentence_list.append(user_input)\n",
        "  bot_response = ''\n",
        "  cm = CountVectorizer().fit_transform(sentence_list)\n",
        "  similarity_scores = cosine_similarity(cm[-1],cm)\n",
        "  #Reducing the dimensionality of the similarity score \n",
        "  similarity_scores_list = similarity_scores.flatten()\n",
        "  #Index that containt the indecies sorted from the highest to the lowest values in similarities scores  \n",
        "  index = index_sort(similarity_scores_list)\n",
        "  # I want index to contain only value that are not itself, from 1 onwards\n",
        "  index = index[1:]\n",
        "  #Flag to see if there is a response back to the user if this similarity function found similarities on the text \n",
        "  #to what the user query input is\n",
        "  response_flag = 0\n",
        "\n",
        "#Bringing two sentences only It´s gona tell me if we found 2 or less similar sentences bringing only the top two \n",
        "# similar sentences to the user´s inputs\n",
        "\n",
        "  j = 0\n",
        "  for i in range(len(index)):\n",
        "  # If it´s greater than 0 we have a similarity to user´s input\n",
        "    if similarity_scores_list[index[i]] > 0.0:\n",
        "      bot_response = bot_response+' '+sentence_list[index[i]]\n",
        "      response_flag = 1\n",
        "    # To know how many scores there are above 0\n",
        "      j = j+1\n",
        "    if j > 2:\n",
        "     break\n",
        "\n",
        "# Case for not having found any similarity\n",
        "  if response_flag == 0:\n",
        "    bot_response = bot_response+' '+ \"My current training status doesn´t allow me to make sense out of that.\"\n",
        "  sentence_list.remove(user_input)\n",
        "\n",
        "  return bot_response\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvixCWSsACVv",
        "outputId": "69a27436-a5ed-4f4b-8ed3-7465cc1b4931"
      },
      "source": [
        "#Starting the chat\n",
        "print('This is a Medical Preliminary assesment Bot. I wil answer your queries concerning chronic kidney diseases.If you want to Exit, type bye')\n",
        "exit_list = ['exit','Hope you get better', 'Stay Well', 'Regards','Bye' ]\n",
        "while(True):\n",
        "  user_input = input()\n",
        "  if user_input.lower() in exit_list:\n",
        "    print('Doc Bot: Chat with you later !')\n",
        "    break\n",
        "  else:\n",
        "    if greeting_response(user_input) != None:\n",
        "      print('Doc Bot: '+greeting_response(user_input))\n",
        "    else:\n",
        "      print('Doc Bot:' +bot_response(user_input))\n",
        "# Next phase requires data preprocessing and cleaning and user input validation of equivalences which is what the \n",
        "#machine learning algorithm would be instrumental for."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a Medical Preliminary assesment Bot. I wil answer your queries concerning chronic kidney diseases.If you want to Exit, type bye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPP-MQ8o0UmF"
      },
      "source": [
        "user_input = 'Hola'\n",
        "sentence_list.append(user_input)\n",
        "bot_response = ''\n",
        "cm = CountVectorizer().fit_transform(sentence_list)\n",
        "similarity_scores = cosine_similarity(cm[-1], cm)\n",
        "#Reducing the dimensionality of the similarity score \n",
        "similarity_scores_list = similarity_scores.flatten()\n",
        "#Index that containt the indecies sorted from the highest to the lowest values in similarities scores  \n",
        "index = index_sort(similarity_scores_list)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeygFpKq1ayj",
        "outputId": "9dd46928-4924-472e-cca3-5ce506d34931"
      },
      "source": [
        "#How similar to any sentence in the text except for the one showing 1 that represents 100% similarity as it is \n",
        "#the text itself.Now I know where the highest values are\n",
        "similarity_scores_list "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ijihMoY2QsG",
        "outputId": "6a862fdb-3c18-476d-df4d-4b1b7e2847c6"
      },
      "source": [
        "index"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 21,\n",
              " 22,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 0,\n",
              " 1,\n",
              " 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}